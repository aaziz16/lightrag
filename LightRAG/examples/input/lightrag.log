2024-11-10 22:46:08,129 - lightrag - INFO - Logger initialized for working directory: input
2024-11-10 22:46:08,131 - lightrag - DEBUG - LightRAG init with param:
  working_dir = input,
  chunk_token_size = 750,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1536, 'max_token_size': 8192, 'func': <function initialize_rag.<locals>.<lambda> at 0x00000144FFC6AFC0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function initialize_rag.<locals>.<lambda> at 0x00000144E5080900>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000144FF6C2E80>

2024-11-10 22:46:08,134 - lightrag - INFO - Load KV full_docs with 0 data
2024-11-10 22:46:08,135 - lightrag - INFO - Load KV text_chunks with 0 data
2024-11-10 22:46:08,136 - lightrag - INFO - Load KV llm_response_cache with 0 data
2024-11-10 22:46:15,975 - lightrag - INFO - [New Docs] inserting 1 docs
2024-11-10 22:46:15,997 - lightrag - INFO - [New Chunks] inserting 13 chunks
2024-11-10 22:46:16,000 - lightrag - INFO - Inserting 13 vectors to chunks
2024-11-10 22:46:16,013 - lightrag - INFO - Logger initialized for working directory: sub_input
2024-11-10 22:46:16,013 - lightrag - DEBUG - LightRAG init with param:
  working_dir = sub_input,
  chunk_token_size = 750,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1536, 'max_token_size': 8192, 'func': <function initialize_rag.<locals>.<lambda> at 0x00000144F4D89F80>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function initialize_rag.<locals>.<lambda> at 0x00000144E5206E80>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000144FF6C2E80>

2024-11-10 22:46:16,013 - lightrag - INFO - Load KV full_docs with 0 data
2024-11-10 22:46:16,013 - lightrag - INFO - Load KV text_chunks with 0 data
2024-11-10 22:46:16,013 - lightrag - INFO - Load KV llm_response_cache with 0 data
2024-11-10 22:46:26,900 - lightrag - INFO - [New Docs] inserting 1 docs
2024-11-10 22:46:26,926 - lightrag - INFO - [New Chunks] inserting 17 chunks
2024-11-10 22:46:26,927 - lightrag - INFO - Inserting 17 vectors to chunks
2024-11-10 22:46:27,586 - lightrag - INFO - [Entity Extraction]...
2024-11-10 22:46:27,853 - lightrag - INFO - [Entity Extraction]...
2024-11-10 22:46:58,444 - lightrag - INFO - Inserting 166 vectors to entities
2024-11-10 22:46:59,354 - lightrag - INFO - Inserting 162 vectors to relationships
2024-11-10 22:47:00,261 - lightrag - INFO - Writing graph with 186 nodes, 162 edges
2024-11-10 22:47:01,315 - lightrag - INFO - Local query uses 60 entites, 79 relations, 5 text units
2024-11-10 22:47:01,560 - lightrag - INFO - Global query uses 73 entites, 60 relations, 5 text units
2024-11-10 22:47:04,274 - lightrag - INFO - Inserting 212 vectors to entities
2024-11-10 22:47:05,475 - lightrag - INFO - Inserting 232 vectors to relationships
2024-11-10 22:47:06,458 - lightrag - INFO - Writing graph with 216 nodes, 232 edges
2024-11-10 22:47:08,368 - lightrag - INFO - Local query uses 60 entites, 93 relations, 6 text units
2024-11-10 22:47:08,648 - lightrag - INFO - Global query uses 63 entites, 60 relations, 5 text units
2024-11-10 22:47:23,453 - lightrag - INFO - Logger initialized for working directory: input
2024-11-10 22:47:23,461 - lightrag - DEBUG - LightRAG init with param:
  working_dir = input,
  chunk_token_size = 750,
  chunk_overlap_token_size = 100,
  tiktoken_model_name = gpt-4o-mini,
  entity_extract_max_gleaning = 1,
  entity_summary_to_max_tokens = 500,
  node_embedding_algorithm = node2vec,
  node2vec_params = {'dimensions': 1536, 'num_walks': 10, 'walk_length': 40, 'window_size': 2, 'iterations': 3, 'random_seed': 3},
  embedding_func = {'embedding_dim': 1536, 'max_token_size': 8192, 'func': <function initialize_rag.<locals>.<lambda> at 0x00000144825CD3A0>},
  embedding_batch_num = 32,
  embedding_func_max_async = 16,
  llm_model_func = <function initialize_rag.<locals>.<lambda> at 0x00000144825CC680>,
  llm_model_name = meta-llama/Llama-3.2-1B-Instruct,
  llm_model_max_token_size = 32768,
  llm_model_max_async = 16,
  key_string_value_json_storage_cls = <class 'lightrag.storage.JsonKVStorage'>,
  vector_db_storage_cls = <class 'lightrag.storage.NanoVectorDBStorage'>,
  vector_db_storage_cls_kwargs = {},
  graph_storage_cls = <class 'lightrag.storage.NetworkXStorage'>,
  enable_llm_cache = True,
  addon_params = {},
  convert_response_to_json_func = <function convert_response_to_json at 0x00000144FF6C2E80>

2024-11-10 22:47:23,482 - lightrag - INFO - Load KV full_docs with 1 data
2024-11-10 22:47:23,484 - lightrag - INFO - Load KV text_chunks with 13 data
2024-11-10 22:47:23,484 - lightrag - INFO - Load KV llm_response_cache with 0 data
2024-11-10 22:47:23,523 - lightrag - INFO - Loaded graph from input\graph_chunk_entity_relation.graphml with 186 nodes, 162 edges
2024-11-10 22:47:25,568 - lightrag - INFO - Local query uses 60 entites, 84 relations, 6 text units
2024-11-10 22:47:25,790 - lightrag - INFO - Global query uses 66 entites, 60 relations, 5 text units
